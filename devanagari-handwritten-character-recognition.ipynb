{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9678039,"sourceType":"datasetVersion","datasetId":5915202}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/devamsheth0806/devanagari-handwritten-character-recognition?scriptVersionId=229332768\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import EfficientNetB0, MobileNetV3Small\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score\n\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-03-24T03:11:28.692819Z","iopub.execute_input":"2025-03-24T03:11:28.69362Z","iopub.status.idle":"2025-03-24T03:11:28.703282Z","shell.execute_reply.started":"2025-03-24T03:11:28.693586Z","shell.execute_reply":"2025-03-24T03:11:28.702575Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"train_path = os.path.join('/kaggle','input','devanagari-handwritten-character-dataset','DevanagariHandwrittenCharacterDataset','Train')\ntest_path = os.path.join('/kaggle','input','devanagari-handwritten-character-dataset','DevanagariHandwrittenCharacterDataset','Test')\noutput_path = os.path.join('/kaggle','working')","metadata":{"execution":{"iopub.status.busy":"2025-03-24T03:11:29.214281Z","iopub.execute_input":"2025-03-24T03:11:29.215006Z","iopub.status.idle":"2025-03-24T03:11:29.219287Z","shell.execute_reply.started":"2025-03-24T03:11:29.21497Z","shell.execute_reply":"2025-03-24T03:11:29.218411Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = tf.keras.utils.image_dataset_from_directory(\n    train_path,\n    label_mode='categorical',\n    batch_size=100,\n    image_size=(32, 32),\n    shuffle=True\n)\n\ntest_dataset = tf.keras.utils.image_dataset_from_directory(\n    test_path,\n    label_mode='categorical',\n    batch_size=100,\n    image_size=(32, 32),\n    shuffle=True\n)\nclass_names = [x.split('_')[-1] for x in train_dataset.class_names]\nprint(f\"Class Names: {class_names}\") ","metadata":{"execution":{"iopub.status.busy":"2025-03-24T03:11:29.240882Z","iopub.execute_input":"2025-03-24T03:11:29.241382Z","iopub.status.idle":"2025-03-24T03:12:05.218284Z","shell.execute_reply.started":"2025-03-24T03:11:29.241329Z","shell.execute_reply":"2025-03-24T03:12:05.21741Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n        layers.RandomRotation(0.1),\n        layers.RandomZoom(0.1),\n        layers.RandomTranslation(0.1, 0.1),\n    ])\ndef preprocess_train(image, label):\n    image = tf.image.convert_image_dtype(image, tf.float32) \n    image = data_augmentation(image)\n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:12:05.220172Z","iopub.execute_input":"2025-03-24T03:12:05.220854Z","iopub.status.idle":"2025-03-24T03:12:05.241596Z","shell.execute_reply.started":"2025-03-24T03:12:05.220812Z","shell.execute_reply":"2025-03-24T03:12:05.240744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_test(image, label):\n    image = tf.image.convert_image_dtype(image, tf.float32)  # Rescale to [0, 1]\n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:12:05.242733Z","iopub.execute_input":"2025-03-24T03:12:05.242994Z","iopub.status.idle":"2025-03-24T03:12:05.248512Z","shell.execute_reply.started":"2025-03-24T03:12:05.242968Z","shell.execute_reply":"2025-03-24T03:12:05.247755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4: Map the preprocessing functions onto datasets\ntrain_dataset = train_dataset.map(preprocess_train, num_parallel_calls=tf.data.AUTOTUNE)\ntest_dataset = test_dataset.map(preprocess_test, num_parallel_calls=tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:12:05.250115Z","iopub.execute_input":"2025-03-24T03:12:05.250379Z","iopub.status.idle":"2025-03-24T03:12:05.480992Z","shell.execute_reply.started":"2025-03-24T03:12:05.250332Z","shell.execute_reply":"2025-03-24T03:12:05.480317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 5: Optimize with caching and prefetching\ntrain_dataset = train_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\ntest_dataset = test_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:12:05.481953Z","iopub.execute_input":"2025-03-24T03:12:05.482223Z","iopub.status.idle":"2025-03-24T03:12:05.491671Z","shell.execute_reply.started":"2025-03-24T03:12:05.482196Z","shell.execute_reply":"2025-03-24T03:12:05.490884Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_images(dataset, title, num_images=9):\n    plt.figure(figsize=(5, 5))\n    for images, labels in dataset.take(1):\n        for i in range(num_images):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(images[i].numpy().astype(\"uint8\"))\n            plt.title(f\"Label: {class_names[tf.argmax(labels[i])]}\")\n            plt.axis(\"off\")\n    plt.suptitle(title)\n    plt.show()\n\nvisualize_images(train_dataset, \"Random Training Images\", num_images=9)\nvisualize_images(test_dataset, \"Random Testing Images\", num_images=9)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:12:05.492666Z","iopub.execute_input":"2025-03-24T03:12:05.492904Z","iopub.status.idle":"2025-03-24T03:12:06.725591Z","shell.execute_reply.started":"2025-03-24T03:12:05.492879Z","shell.execute_reply":"2025-03-24T03:12:06.724718Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PCA","metadata":{}},{"cell_type":"markdown","source":"Transforming training images for PCA","metadata":{}},{"cell_type":"code","source":"train_images, train_labels = [], []\nfor images, labels in train_dataset:\n    train_images.append(images.numpy())\n    train_labels.append(labels.numpy())\n\nprint(\"Step 1: Converted TensorFlow dataset to NumPy arrays.\")\nprint(\"Number of batches in train_images:\", len(train_images))\nprint(\"Shape of a batch in train_images:\", train_images[0].shape)\n\n# Flatten the images and prepare them for PCA\ntrain_images_np = np.concatenate(train_images, axis=0)  # Combine all batches\nprint(\"Step 2: Combined all batches into one NumPy array.\")\nprint(\"Shape of combined train_images_np:\", train_images_np.shape)\n\ntrain_images_flattened = train_images_np.reshape(train_images_np.shape[0], -1)  # Flatten each image into a vector\nprint(\"Step 3: Flattened each image into a vector.\")\nprint(\"Shape of flattened train_images_flattened:\", train_images_flattened.shape)\n\n# Conduct PCA using the custom step-by-step implementation\npca_impl = PCA(n_components=0.88)\n\ntrain_images_pca = pca_impl.fit_transform(train_images_flattened)\nprint(\"Step 5: Conducted PCA on the flattened images.\")\nprint(\"Original shape:\", train_images_flattened.shape)\nprint(\"Transformed shape:\", train_images_pca.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:12:06.726701Z","iopub.execute_input":"2025-03-24T03:12:06.726971Z","iopub.status.idle":"2025-03-24T03:13:49.614901Z","shell.execute_reply.started":"2025-03-24T03:12:06.726945Z","shell.execute_reply":"2025-03-24T03:13:49.61417Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Transforming Test images","metadata":{}},{"cell_type":"code","source":"test_images, test_labels = [], []\nfor images, labels in test_dataset:\n    test_images.append(images.numpy())\n    test_labels.append(labels.numpy())\n\nprint(\"Step 1: Converted TensorFlow dataset to NumPy arrays.\")\nprint(\"Number of batches in test_images:\", len(test_images))\nprint(\"Shape of a batch in test_images:\", test_images[0].shape)\n\n# Flatten the images and prepare them for PCA\ntest_images_np = np.concatenate(test_images, axis=0)  # Combine all batches\nprint(\"Step 2: Combined all batches into one NumPy array.\")\nprint(\"Shape of combined test_images_np:\", test_images_np.shape)\n\ntest_images_flattened = test_images_np.reshape(test_images_np.shape[0], -1)  # Flatten each image into a vector\nprint(\"Step 3: Flattened each image into a vector.\")\nprint(\"Shape of flattened test_images_flattened:\", test_images_flattened.shape)\n\n# Conduct PCA using the custom step-by-step implementation\ntest_images_pca = pca_impl.transform(test_images_flattened)\nprint(\"Step 5: Conducted PCA on the flattened images.\")\nprint(\"Original shape:\", test_images_flattened.shape)\nprint(\"Transformed shape:\", test_images_pca.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:13:49.615927Z","iopub.execute_input":"2025-03-24T03:13:49.616188Z","iopub.status.idle":"2025-03-24T03:13:58.32858Z","shell.execute_reply.started":"2025-03-24T03:13:49.616162Z","shell.execute_reply":"2025-03-24T03:13:58.327347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Eigen values \ndef plot_explained_variance(eigenvalues, n_components):\n    total_variance = np.sum(eigenvalues)\n    explained_variance_ratio = [(i / total_variance) for i in sorted(eigenvalues, reverse=True)]\n    cumulative_variance = np.cumsum(explained_variance_ratio)\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n    plt.xlabel('Number of Principal Components')\n    plt.ylabel('Cumulative Explained Variance')\n    plt.title('Explained Variance vs. Number of Components')\n    plt.grid()\n    plt.show()\n\n    for i, variance in enumerate(cumulative_variance):\n        if abs(variance - n_components)<=0.01: \n            print(f\"Component {i+1}: Cumulative Explained Variance = {variance:.4f}\")\n\n# Plotting Explained Variance\nplot_explained_variance(pca_impl.explained_variance_, pca_impl.n_components)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:13:58.329973Z","iopub.execute_input":"2025-03-24T03:13:58.330492Z","iopub.status.idle":"2025-03-24T03:13:58.618672Z","shell.execute_reply.started":"2025-03-24T03:13:58.330432Z","shell.execute_reply":"2025-03-24T03:13:58.617827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reshape reduced data back to image dimensions for visualization (if possible)\nnum_samples_to_plot = 5\nreconstructed_images = pca_impl.inverse_transform(train_images_pca[:num_samples_to_plot])\nreconstructed_images = reconstructed_images.reshape((num_samples_to_plot, 32, 32, 3))\n\n# Plot original vs reconstructed images\nplt.figure(figsize=(10, 4))\nfor i in range(num_samples_to_plot):\n    # Original Image\n    plt.subplot(2, num_samples_to_plot, i + 1)\n    plt.imshow(train_images_np[i].astype('uint8'))\n    plt.title(\"Original\")\n    plt.axis('off')\n\n    # Reconstructed Image\n    plt.subplot(2, num_samples_to_plot, num_samples_to_plot + i + 1)\n    plt.imshow(reconstructed_images[i].astype('uint8'))\n    plt.title(\"Reconstructed\")\n    plt.axis('off')\n\nplt.suptitle(\"Original vs Reconstructed Images After PCA\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:13:58.621277Z","iopub.execute_input":"2025-03-24T03:13:58.621563Z","iopub.status.idle":"2025-03-24T03:13:59.385163Z","shell.execute_reply.started":"2025-03-24T03:13:58.621535Z","shell.execute_reply":"2025-03-24T03:13:59.384428Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Machine Learning Models","metadata":{}},{"cell_type":"markdown","source":"### Generic Classifier function","metadata":{}},{"cell_type":"code","source":"def genericClassifier(clfr, x_train_data, y_train_data, x_test_data, y_test_data, acc_str, matrix_header_str):\n    clfr.fit(x_train_data, y_train_data)\n    y_pred = clfr.predict(x_test_data)\n\n    print(acc_str.format(accuracy_score(y_test_data, y_pred) * 100))\n    acc = accuracy_score(y_test_data, y_pred) * 100\n    f1 = f1_score(y_test_data.argmax(axis=1), y_pred.argmax(axis=1), average='weighted') if len(y_test_data.shape) > 1 else f1_score(y_test_data, y_pred, average='weighted')\n    print(\"F1 Score =\", f1)\n    return y_pred, acc, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:13:59.38643Z","iopub.execute_input":"2025-03-24T03:13:59.386803Z","iopub.status.idle":"2025-03-24T03:13:59.392455Z","shell.execute_reply.started":"2025-03-24T03:13:59.386753Z","shell.execute_reply":"2025-03-24T03:13:59.391637Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Gaussian Naive Bayes Classifier","metadata":{}},{"cell_type":"code","source":"train_labels= np.concatenate(train_labels, axis=0)  # Merges into one array\ntest_labels= np.concatenate(test_labels, axis=0)  # Merges into one array","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:13:59.39345Z","iopub.execute_input":"2025-03-24T03:13:59.393764Z","iopub.status.idle":"2025-03-24T03:13:59.410487Z","shell.execute_reply.started":"2025-03-24T03:13:59.393737Z","shell.execute_reply":"2025-03-24T03:13:59.409599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"naiveBayesClassifier = GaussianNB(var_smoothing=1e-8)\ny_pred_nb, nb_acc, nb_f1 = genericClassifier(\n    naiveBayesClassifier,\n    train_images_pca,\n    train_labels.argmax(axis=1),\n    test_images_pca,\n    test_labels.argmax(axis=1),\n    \"Naive Bayes Accuracy: {0:0.1f}%\", \"Naive Bayes Confusion matrix\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:13:59.411728Z","iopub.execute_input":"2025-03-24T03:13:59.411982Z","iopub.status.idle":"2025-03-24T03:13:59.664015Z","shell.execute_reply.started":"2025-03-24T03:13:59.411957Z","shell.execute_reply":"2025-03-24T03:13:59.663115Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### KNN","metadata":{}},{"cell_type":"code","source":"knnClassifier = KNeighborsClassifier(n_neighbors=10, weights='distance', algorithm='ball_tree', n_jobs=-1)\ny_pred_knn, knn_acc, knn_f1 = genericClassifier(\n    knnClassifier, \n    train_images_pca,\n    train_labels.argmax(axis=1),\n    test_images_pca,\n    test_labels.argmax(axis=1),\n    \"KNN Accuracy: {0:0.1f}%\", \"KNN Confusion matrix\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:13:59.665226Z","iopub.execute_input":"2025-03-24T03:13:59.665866Z","iopub.status.idle":"2025-03-24T03:15:07.557287Z","shell.execute_reply.started":"2025-03-24T03:13:59.665822Z","shell.execute_reply":"2025-03-24T03:15:07.556442Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Multi-Layer Perceptron (for Shallow neural network)","metadata":{}},{"cell_type":"code","source":"mlpClassifier = MLPClassifier(hidden_layer_sizes=(64, 128, 256), max_iter = 400)\ny_pred_mlp, mlp_acc, mlp_f1 = genericClassifier(\n    mlpClassifier, \n    train_images_pca,\n    train_labels.argmax(axis=1),\n    test_images_pca,\n    test_labels.argmax(axis=1),\n    \"MLP Classifier Accuracy: {0:0.1f}%\", \"MLP Classifier Confusion matrix\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:15:07.558983Z","iopub.execute_input":"2025-03-24T03:15:07.559748Z","iopub.status.idle":"2025-03-24T03:21:45.763256Z","shell.execute_reply.started":"2025-03-24T03:15:07.559696Z","shell.execute_reply":"2025-03-24T03:21:45.761345Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Deep Learning Models","metadata":{}},{"cell_type":"markdown","source":"### CNN","metadata":{}},{"cell_type":"code","source":"input_shape = (32, 32, 3)\nnum_classes = len(class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:21:45.76446Z","iopub.execute_input":"2025-03-24T03:21:45.76484Z","iopub.status.idle":"2025-03-24T03:21:45.773155Z","shell.execute_reply.started":"2025-03-24T03:21:45.764797Z","shell.execute_reply":"2025-03-24T03:21:45.771917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def vanilla_cnn(input_shape, num_classes):\n    model = tf.keras.Sequential([\n        # First Convolutional Block\n        layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=input_shape),\n        layers.MaxPooling2D((2, 2)),\n        layers.BatchNormalization(),\n        \n        # Second Convolutional Block\n        layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n        layers.BatchNormalization(),\n        # layers.Dropout(0.3),\n        # Third Convolutional Block\n        layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n        layers.MaxPooling2D((2, 2)),\n        layers.BatchNormalization(),\n\n        # Fully Connected Layers\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.4),\n\n        layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n\n        # Output Layer\n        layers.Dense(num_classes, activation='softmax')\n    ])\n\n    # Compile the model\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy','f1_score'])\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:21:45.775766Z","iopub.execute_input":"2025-03-24T03:21:45.777547Z","iopub.status.idle":"2025-03-24T03:21:45.79559Z","shell.execute_reply.started":"2025-03-24T03:21:45.777473Z","shell.execute_reply":"2025-03-24T03:21:45.793248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vanilla CNN\nvanilla_cnn_model = vanilla_cnn(input_shape, num_classes)\nhistory_cnn = vanilla_cnn_model.fit(train_dataset, validation_data=test_dataset, epochs=30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:21:45.799412Z","iopub.execute_input":"2025-03-24T03:21:45.799944Z","iopub.status.idle":"2025-03-24T03:24:10.396015Z","shell.execute_reply.started":"2025-03-24T03:21:45.799885Z","shell.execute_reply":"2025-03-24T03:24:10.395324Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loss, train_accuracy, _ = vanilla_cnn_model.evaluate(train_dataset)\nvalidate_loss, validate_accuracy, _ = vanilla_cnn_model.evaluate(test_dataset)\nprint(\"Train: accuracy = %f  ;  loss_v = %f\" % (train_accuracy, train_loss))\nprint(\"Validation: accuracy = %f  ;  loss_v = %f\" % (validate_accuracy, validate_loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:24:10.396978Z","iopub.execute_input":"2025-03-24T03:24:10.397248Z","iopub.status.idle":"2025-03-24T03:24:12.727833Z","shell.execute_reply.started":"2025-03-24T03:24:10.397221Z","shell.execute_reply":"2025-03-24T03:24:12.726917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def efficientnet_model(input_shape, num_classes):\n    base_model = tf.keras.applications.EfficientNetB0(\n        input_shape=input_shape,\n        include_top=False,\n        weights='imagenet'\n    )\n    # base_model.trainable = False  # Freeze base model layers initially\n\n    model = tf.keras.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(64, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(32, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),#'adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy', 'f1_score'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:24:12.729029Z","iopub.execute_input":"2025-03-24T03:24:12.729435Z","iopub.status.idle":"2025-03-24T03:24:12.735679Z","shell.execute_reply.started":"2025-03-24T03:24:12.72939Z","shell.execute_reply":"2025-03-24T03:24:12.734774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# EfficientNet\nefficientnet = efficientnet_model(input_shape, num_classes)\nhistory_efficient = efficientnet.fit(train_dataset, validation_data=test_dataset, epochs=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:24:12.73671Z","iopub.execute_input":"2025-03-24T03:24:12.736961Z","iopub.status.idle":"2025-03-24T03:31:10.601836Z","shell.execute_reply.started":"2025-03-24T03:24:12.736936Z","shell.execute_reply":"2025-03-24T03:31:10.600925Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loss, train_accuracy, _ = efficientnet.evaluate(train_dataset)\nvalidate_loss, validate_accuracy, _ = efficientnet.evaluate(test_dataset)\nprint(\"Train: accuracy = %f  ;  loss_v = %f\" % (train_accuracy, train_loss))\nprint(\"Validation: accuracy = %f  ;  loss_v = %f\" % (validate_accuracy, validate_loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:31:10.602965Z","iopub.execute_input":"2025-03-24T03:31:10.603215Z","iopub.status.idle":"2025-03-24T03:31:16.393544Z","shell.execute_reply.started":"2025-03-24T03:31:10.603189Z","shell.execute_reply":"2025-03-24T03:31:16.392832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mobilenet_model(input_shape, num_classes):\n    base_model = tf.keras.applications.MobileNetV3Small(\n        input_shape=input_shape,\n        include_top=False,\n        weights='imagenet'\n    )\n    # base_model.trainable = False  # Freeze base model layers initially\n\n    model = tf.keras.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),#'adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy','f1_score'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:31:16.394684Z","iopub.execute_input":"2025-03-24T03:31:16.395282Z","iopub.status.idle":"2025-03-24T03:31:16.40088Z","shell.execute_reply.started":"2025-03-24T03:31:16.395237Z","shell.execute_reply":"2025-03-24T03:31:16.400058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MobileNet\nmobilenet = mobilenet_model(input_shape, num_classes)\nhistory_mobilenet = mobilenet.fit(train_dataset, validation_data=test_dataset, epochs=20)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-03-24T03:31:16.4021Z","iopub.execute_input":"2025-03-24T03:31:16.402787Z","iopub.status.idle":"2025-03-24T03:34:48.774945Z","shell.execute_reply.started":"2025-03-24T03:31:16.402743Z","shell.execute_reply":"2025-03-24T03:34:48.77407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loss, train_accuracy, _ = mobilenet.evaluate(train_dataset)\nvalidate_loss, validate_accuracy, _ = mobilenet.evaluate(test_dataset)\nprint(\"Train: accuracy = %f  ;  loss_v = %f\" % (train_accuracy, train_loss))\nprint(\"Validation: accuracy = %f  ;  loss_v = %f\" % (validate_accuracy, validate_loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:34:48.77628Z","iopub.execute_input":"2025-03-24T03:34:48.776656Z","iopub.status.idle":"2025-03-24T03:34:52.538581Z","shell.execute_reply.started":"2025-03-24T03:34:48.776623Z","shell.execute_reply":"2025-03-24T03:34:52.537796Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Deep Belief Networks","metadata":{}},{"cell_type":"code","source":"def extract_data(dataset):\n    images, labels = [], []\n    for img_batch, label_batch in dataset:\n        images.extend(img_batch.numpy().reshape(len(img_batch), -1))  # Flatten images\n        labels.extend(tf.argmax(label_batch, axis=1).numpy())  # Decode one-hot labels\n    return np.array(images) / 255.0, np.array(labels)\n\n# Extract data from train_dataset and test_dataset\ntrain_images, train_labels = extract_data(train_dataset)\ntest_images, test_labels = extract_data(test_dataset)\n\n# One-hot encode labels for DBN fine-tuning\nnum_classes = len(class_names)\ntrain_labels_onehot = tf.keras.utils.to_categorical(train_labels, num_classes)\ntest_labels_onehot = tf.keras.utils.to_categorical(test_labels, num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:34:52.539582Z","iopub.execute_input":"2025-03-24T03:34:52.539857Z","iopub.status.idle":"2025-03-24T03:34:54.444845Z","shell.execute_reply.started":"2025-03-24T03:34:52.539829Z","shell.execute_reply":"2025-03-24T03:34:54.444083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RBM(tf.keras.layers.Layer):\n    def __init__(self, visible_units, hidden_units, learning_rate=0.01):\n        super(RBM, self).__init__()\n        self.visible_units = visible_units\n        self.hidden_units = hidden_units\n        self.learning_rate = learning_rate\n        self.built = False\n\n    def build(self, input_shape):\n        # Initialize weights and biases with unique names\n        self.rbm_weights = self.add_weight(\n            shape=(self.visible_units, self.hidden_units),\n            initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1),\n            trainable=True,\n            name=\"rbm_weights\"\n        )\n        self.hidden_bias = self.add_weight(\n            shape=(self.hidden_units,),\n            initializer=\"zeros\",\n            trainable=True,\n            name=\"hidden_bias\"\n        )\n        self.visible_bias = self.add_weight(\n            shape=(self.visible_units,),\n            initializer=\"zeros\",\n            trainable=True,\n            name=\"visible_bias\"\n        )\n        self.built = True\n\n    def forward(self, visible):\n        # Ensure weights are initialized\n        if not self.built:\n            self.build((None, visible.shape[1]))\n        hidden_prob = tf.nn.sigmoid(tf.matmul(visible, self.rbm_weights) + self.hidden_bias)\n        hidden_states = tf.cast(hidden_prob > tf.random.uniform(tf.shape(hidden_prob)), tf.float32)\n        return hidden_prob, hidden_states\n\n    def backward(self, hidden):\n        visible_prob = tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(self.rbm_weights)) + self.visible_bias)\n        return visible_prob\n\n    def train(self, inputs):\n        # Forward pass\n        hidden_prob, hidden_states = self.forward(inputs)\n\n        # Backward pass\n        reconstructed_visible_prob = self.backward(hidden_states)\n        reconstructed_hidden_prob, _ = self.forward(reconstructed_visible_prob)\n\n        # Compute gradients\n        positive_grad = tf.matmul(tf.transpose(inputs), hidden_prob)\n        negative_grad = tf.matmul(tf.transpose(reconstructed_visible_prob), reconstructed_hidden_prob)\n\n        # Update weights and biases\n        self.rbm_weights.assign_add(self.learning_rate * (positive_grad - negative_grad) / tf.cast(tf.shape(inputs)[0], tf.float32))\n        self.visible_bias.assign_add(self.learning_rate * tf.reduce_mean(inputs - reconstructed_visible_prob, axis=0))\n        self.hidden_bias.assign_add(self.learning_rate * tf.reduce_mean(hidden_prob - reconstructed_hidden_prob, axis=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:34:54.446001Z","iopub.execute_input":"2025-03-24T03:34:54.446271Z","iopub.status.idle":"2025-03-24T03:34:54.456197Z","shell.execute_reply.started":"2025-03-24T03:34:54.446245Z","shell.execute_reply":"2025-03-24T03:34:54.455403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DBN:\n    def __init__(self, layer_sizes, learning_rate=0.01):\n        self.layer_sizes = layer_sizes\n        self.learning_rate = learning_rate\n        self.rbms = [RBM(layer_sizes[i], layer_sizes[i + 1], learning_rate) for i in range(len(layer_sizes) - 1)]\n\n    def pretrain(self, data, epochs=10):\n        input_data = data\n        for i, rbm in enumerate(self.rbms):\n            print(f\"Training RBM {i + 1}/{len(self.rbms)}\")\n            for epoch in range(epochs):\n                rbm.train(input_data)\n            input_data, _ = rbm.forward(input_data)\n\n    def fine_tune(self, data, labels, epochs=10, dropout_rate = 0.3):\n        model = tf.keras.Sequential()\n        input_size = self.layer_sizes[0]  # Start with the input size of the data\n\n        i = 0\n        # Add layers corresponding to pretrained RBMs\n        for rbm in self.rbms:\n            # Add Dense layer without initializing weights\n            dense_layer = tf.keras.layers.Dense(\n                rbm.hidden_units,\n                activation=\"sigmoid\",\n                trainable=True\n            )\n            model.add(dense_layer)\n    \n            # Force the layer to build by providing the correct input shape\n            dense_layer.build(input_shape=(None, input_size))\n    \n            # Set the pretrained weights and biases\n            dense_layer.set_weights([rbm.rbm_weights.numpy(), rbm.hidden_bias.numpy()])\n\n            # adding drop layer\n            if i%2==0:\n                model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n                i+=1\n\n            model.add(layers.BatchNormalization())\n            \n            # Update input size for the next layer\n            input_size = rbm.hidden_units\n    \n        # Add final classification layer\n        model.add(\n            tf.keras.layers.Dense(\n                labels.shape[1],\n                activation=\"softmax\"\n            )\n        )\n    \n        # Compile the model\n        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"f1_score\"])\n    \n        # Train the model\n        history = model.fit(data, labels, epochs=epochs, validation_split=0.2)\n        return model, history\n    def predict(self, data):\n        # Forward pass through all the RBMs (unsupervised feature extraction)\n        input_data = data\n        for rbm in self.rbms:\n            # Compute the hidden probabilities and use them as input to the next RBM\n            hidden_prob, _ = rbm.forward(input_data)\n            input_data = hidden_prob\n    \n        # Forward pass through the fine-tuned model (supervised prediction)\n        predictions = self.fine_tuned_model.predict(input_data)\n        predicted_labels = np.argmax(predictions, axis=1)  # Convert probabilities to class labels\n    \n        return predicted_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:34:54.460854Z","iopub.execute_input":"2025-03-24T03:34:54.461086Z","iopub.status.idle":"2025-03-24T03:34:54.471113Z","shell.execute_reply.started":"2025-03-24T03:34:54.461063Z","shell.execute_reply":"2025-03-24T03:34:54.470303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define DBN architecture\ninput_dim = train_images.shape[1]  # Number of flattened input features\nlayer_sizes = [input_dim, 1024, 512, 512]  # Input layer and two hidden layers\n\n# Initialize the DBN\ndbn = DBN(layer_sizes, learning_rate=0.01)\n\n# Pretrain the DBN\ndbn.pretrain(train_images, epochs=15)\n\n# Fine-tune the DBN for classification\nmodel, history_dbn = dbn.fine_tune(train_images, train_labels_onehot, epochs=60)\n\n# Evaluate the DBN\ntest_loss, test_accuracy, results = model.evaluate(test_images, test_labels_onehot)\nprint(f\"Test Accuracy: {test_accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:34:54.472115Z","iopub.execute_input":"2025-03-24T03:34:54.472383Z","iopub.status.idle":"2025-03-24T03:43:01.125942Z","shell.execute_reply.started":"2025-03-24T03:34:54.472333Z","shell.execute_reply":"2025-03-24T03:43:01.125073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loss, train_accuracy, results = model.evaluate(test_images, test_labels_onehot)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:43:01.127094Z","iopub.execute_input":"2025-03-24T03:43:01.127419Z","iopub.status.idle":"2025-03-24T03:43:02.076025Z","shell.execute_reply.started":"2025-03-24T03:43:01.127346Z","shell.execute_reply":"2025-03-24T03:43:02.075409Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plots","metadata":{}},{"cell_type":"markdown","source":"### Plotting history","metadata":{}},{"cell_type":"code","source":"def plot_model_history(hist, model_name):\n    tr_acc = hist.history['accuracy']\n    tr_loss = hist.history['loss']\n    val_acc = hist.history['val_accuracy']\n    val_loss = hist.history['val_loss']\n    index_loss = np.argmin(val_loss)\n    val_lowest = val_loss[index_loss]\n    index_acc = np.argmax(val_acc)\n    acc_highest = val_acc[index_acc]\n\n    plt.figure(figsize= (20, 8))\n    plt.style.use('fivethirtyeight')\n    Epochs = [i+1 for i in range(len(tr_acc))]\n    loss_label = f'best epoch= {str(index_loss + 1)}'\n    acc_label = f'best epoch= {str(index_acc + 1)}'\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n    plt.title(f'Training and Validation Loss: {model_name}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n    plt.title(f'Training and Validation Accuracy: {model_name}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:43:02.077416Z","iopub.execute_input":"2025-03-24T03:43:02.077778Z","iopub.status.idle":"2025-03-24T03:43:02.086413Z","shell.execute_reply.started":"2025-03-24T03:43:02.077737Z","shell.execute_reply":"2025-03-24T03:43:02.085596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_confusion_matrix(model, test_dataset, class_names):\n    \"\"\"\n    Plots a formatted confusion matrix for better readability.\n    :param model: Trained model to evaluate.\n    :param test_dataset: Dataset to test the model on.\n    :param class_names: List of class labels.\n    \"\"\"\n    # Get true labels and predictions\n    y_true = []\n    y_pred = []\n\n    for images, labels in test_dataset:\n        # True labels\n        y_true.extend(np.argmax(labels.numpy(), axis=1))\n        # Predicted labels\n        predictions = model.predict(images)\n        y_pred.extend(np.argmax(predictions, axis=1))\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n\n    # Plot the confusion matrix with formatting\n    fig, ax = plt.subplots(figsize=(12, 12))  # Adjust the figure size for readability\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n    disp.plot(\n        include_values=True,  # Show values inside the matrix\n        cmap=plt.cm.Blues,    # Use a color map\n        xticks_rotation=45,   # Rotate x-axis labels\n        ax=ax                 # Use the custom-sized figure\n    )\n    ax.set_title(\"Confusion Matrix\")\n    ax.set_xlabel(\"Predicted Label\")\n    ax.set_ylabel(\"True Label\")\n    plt.tight_layout()  # Adjust layout to prevent clipping\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:43:02.087503Z","iopub.execute_input":"2025-03-24T03:43:02.087813Z","iopub.status.idle":"2025-03-24T03:43:02.09895Z","shell.execute_reply.started":"2025-03-24T03:43:02.087768Z","shell.execute_reply":"2025-03-24T03:43:02.098151Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_model_history(history_cnn,'CNN')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:43:02.099776Z","iopub.execute_input":"2025-03-24T03:43:02.100007Z","iopub.status.idle":"2025-03-24T03:43:02.594413Z","shell.execute_reply.started":"2025-03-24T03:43:02.099982Z","shell.execute_reply":"2025-03-24T03:43:02.593588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_model_history(history_efficient,'Efficient Net')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:43:02.595779Z","iopub.execute_input":"2025-03-24T03:43:02.596044Z","iopub.status.idle":"2025-03-24T03:43:03.137262Z","shell.execute_reply.started":"2025-03-24T03:43:02.596017Z","shell.execute_reply":"2025-03-24T03:43:03.1364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_model_history(history_mobilenet,'Mobile Net')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:43:03.138315Z","iopub.execute_input":"2025-03-24T03:43:03.138617Z","iopub.status.idle":"2025-03-24T03:43:03.630242Z","shell.execute_reply.started":"2025-03-24T03:43:03.138588Z","shell.execute_reply":"2025-03-24T03:43:03.629247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_model_history(history_dbn,'DBN')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T03:43:03.631382Z","iopub.execute_input":"2025-03-24T03:43:03.631695Z","iopub.status.idle":"2025-03-24T03:43:04.153886Z","shell.execute_reply.started":"2025-03-24T03:43:03.631665Z","shell.execute_reply":"2025-03-24T03:43:04.152975Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Confusion Matrix","metadata":{}},{"cell_type":"code","source":"_ = plot_confusion_matrix(vanilla_cnn_model, test_dataset, class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T04:03:11.405175Z","iopub.execute_input":"2025-03-24T04:03:11.405574Z","iopub.status.idle":"2025-03-24T04:03:24.033716Z","shell.execute_reply.started":"2025-03-24T04:03:11.405529Z","shell.execute_reply":"2025-03-24T04:03:24.032912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_confusion_matrix(efficientnet, test_dataset, class_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_confusion_matrix(mobilenet, test_dataset, class_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}